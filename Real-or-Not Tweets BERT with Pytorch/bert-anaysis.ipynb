{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk import word_tokenize\nfrom keras.preprocessing.text import Tokenizer\nfrom nltk.stem.wordnet import WordNetLemmatizer\n#nltk.download('punkt')\n#nltk.download('stopwords')\n#nltk.download('wordnet')\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"},{"output_type":"stream","text":"/kaggle/input/nlp-getting-started/train.csv\n/kaggle/input/nlp-getting-started/test.csv\n/kaggle/input/nlp-getting-started/sample_submission.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\n\n# If there's a GPU available...\nif torch.cuda.is_available():    \n\n    # Tell PyTorch to use the GPU.    \n    device = torch.device(\"cuda\")\n\n    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n\n    print('We will use the GPU:', torch.cuda.get_device_name(0))\n\n# If not...\nelse:\n    print('No GPU available, using the CPU instead.')\n    device = torch.device(\"cpu\")","execution_count":2,"outputs":[{"output_type":"stream","text":"There are 1 GPU(s) available.\nWe will use the GPU: Tesla P100-PCIE-16GB\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")\nsubmission = pd.read_csv(\"/kaggle/input/nlp-getting-started/sample_submission.csv\")","execution_count":141,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure()\nfig.add_trace(go.Bar(x = train.target.value_counts().index,\n             y = train.target.value_counts(),\n             marker_color='Orange'))\nfig.update_layout(width=800, height = 500, title = \"Frequency of Target\")\nfig.show()","execution_count":142,"outputs":[{"output_type":"display_data","data":{"text/html":"<div>\n        \n        \n            <div id=\"a64f3ab8-9f46-40bb-8be1-aec45fcf9138\" class=\"plotly-graph-div\" style=\"height:500px; width:800px;\"></div>\n            <script type=\"text/javascript\">\n                require([\"plotly\"], function(Plotly) {\n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    \n                if (document.getElementById(\"a64f3ab8-9f46-40bb-8be1-aec45fcf9138\")) {\n                    Plotly.newPlot(\n                        'a64f3ab8-9f46-40bb-8be1-aec45fcf9138',\n                        [{\"marker\": {\"color\": \"Orange\"}, \"type\": \"bar\", \"x\": [0, 1], \"y\": [4342, 3271]}],\n                        {\"height\": 500, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Frequency of Target\"}, \"width\": 800},\n                        {\"responsive\": true}\n                    ).then(function(){\n                            \nvar gd = document.getElementById('a64f3ab8-9f46-40bb-8be1-aec45fcf9138');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })\n                };\n                });\n            </script>\n        </div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['text_clean'] = train['text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\ntest['text_clean'] = test['text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))","execution_count":143,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from bs4 import BeautifulSoup\ndef strip_html(text):\n    soup = BeautifulSoup(text, \"html.parser\")\n    return soup.get_text()\n\ndef remove_between_square_brackets(text):\n    return re.sub('\\[[^]]*\\]', '', text)\n\ndef denoise_text(text):\n    text = strip_html(text)\n    text = remove_between_square_brackets(text)\n    return text\n\n\nprint(\"Data cleaning in progress...\")\ntrain[\"text_clean\"] = train[\"text_clean\"].apply(denoise_text)\ntest[\"text_clean\"] = test[\"text_clean\"].apply(denoise_text)\n\n\n","execution_count":144,"outputs":[{"output_type":"stream","text":"Data cleaning in progress...\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import string\ndef clean_text(text):\n    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n    and remove words containing numbers.'''\n    text = text.lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    return text\n\n\ndef text_preprocessing(text):\n\n    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n    \n    nopunc = clean_text(text)\n    tokenized_text = tokenizer.tokenize(nopunc)\n    remove_stopwords = [w for w in tokenized_text if w not in stoplist_combined]\n    combined_text = ' '.join(remove_stopwords)\n    return combined_text\n\n\ntrain[\"text_clean\"] = train[\"text_clean\"].apply(lambda x: text_preprocessing(x))\ntest[\"text_clean\"] = test[\"text_clean\"].apply(lambda x: text_preprocessing(x))","execution_count":145,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stopwords_set= set(['br', 'the', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n            'won', \"won't\", 'wouldn', \"wouldn't\",\"im\",\"youre\",\"I'd\",\"I\",\"Shes\",\"she's\",\"She's\",\"but\",\"But\",\"its\",\"shes\",\"hes\",\"Hes\"])\n\nx = stopwords.words(\"english\")\nstopwords_nltk_en = set(x)\nstoplist_combined = set.union(stopwords_set, stopwords_nltk_en)\ntrain[\"text_clean\"] = train['text_clean'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stoplist_combined)]))\ntest[\"text_clean\"] = test['text_clean'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stoplist_combined)]))\nprint(\"Stop words removed.\")","execution_count":146,"outputs":[{"output_type":"stream","text":"Stop words removed.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":147,"outputs":[{"output_type":"execute_result","execution_count":147,"data":{"text/plain":"   id keyword location                                               text  \\\n0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n\n   target                                         text_clean  \n0       1       deeds reason earthquake may allah forgive us  \n1       1              forest fire near la ronge sask canada  \n2       1  residents asked shelter place notified officer...  \n3       1  people receive wildfires evacuation orders cal...  \n4       1  got sent photo ruby alaska smoke wildfires pou...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n      <th>text_clean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n      <td>deeds reason earthquake may allah forgive us</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n      <td>forest fire near la ronge sask canada</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n      <td>residents asked shelter place notified officer...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n      <td>people receive wildfires evacuation orders cal...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n      <td>got sent photo ruby alaska smoke wildfires pou...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from transformers import BertTokenizer\n\n# Load the BERT tokenizer.\nprint('Loading BERT tokenizer...')\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)","execution_count":148,"outputs":[{"output_type":"stream","text":"Loading BERT tokenizer...\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print the original sentence.\nprint(' Original: ', train[\"text_clean\"][0])\n\n# Print the sentence split into tokens.\nprint('Tokenized: ', tokenizer.tokenize(train[\"text_clean\"][0]))\n\n# Print the sentence mapped to token ids.\nprint('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(train[\"text_clean\"][0])))","execution_count":149,"outputs":[{"output_type":"stream","text":" Original:  deeds reason earthquake may allah forgive us\nTokenized:  ['deeds', 'reason', 'earthquake', 'may', 'allah', 'forgive', 'us']\nToken IDs:  [15616, 3114, 8372, 2089, 16455, 9641, 2149]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_len = 0\n\ntexts = train[\"text_clean\"]\n\n# For every sentence...\nfor text in texts:\n\n    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n    input_ids = tokenizer.encode(text, add_special_tokens=True)\n\n    # Update the maximum sentence length.\n    max_len = max(max_len, len(input_ids))\n\nprint('Max sentence length: ', max_len)","execution_count":150,"outputs":[{"output_type":"stream","text":"Max sentence length:  37\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = train[\"target\"]\nimport torch\ninput_ids = []\nattention_masks = []\n\nfor text in texts:\n\n    encoded_dict = tokenizer.encode_plus(\n                        text,                      # Sentence to encode.\n                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n                        max_length = 50,           # Pad & truncate all sentences.\n                        pad_to_max_length = True,\n                        return_attention_mask = True,   # Construct attn. masks.\n                        return_tensors = 'pt',     # Return pytorch tensors.\n                   )\n    \n    # Add the encoded sentence to the list.    \n    input_ids.append(encoded_dict['input_ids'])\n    \n    # And its attention mask (simply differentiates padding from non-padding).\n    attention_masks.append(encoded_dict['attention_mask'])\n\n# Convert the lists into tensors.\ninput_ids = torch.cat(input_ids, dim=0)\nattention_masks = torch.cat(attention_masks, dim=0)\nlabels = torch.tensor(labels)\n\n# Print sentence 0, now as a list of IDs.\nprint('Original: ', texts[0])\nprint('Token IDs:', input_ids[0])","execution_count":180,"outputs":[{"output_type":"stream","text":"Original:  deeds reason earthquake may allah forgive us\nToken IDs: tensor([  101, 15616,  3114,  8372,  2089, 16455,  9641,  2149,   102,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.data import TensorDataset, random_split\n\n# Combine the training inputs into a TensorDataset.\ndataset = TensorDataset(input_ids, attention_masks, labels)\n\n# Create a 70-30 train-validation split.\n\n# Calculate the number of samples to include in each set.\ntrain_size = int(0.9 * len(dataset))\nval_size = len(dataset) - train_size\n\n# Divide the dataset by randomly selecting samples.\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\nprint('{:>5,} training samples'.format(train_size))\nprint('{:>5,} validation samples'.format(val_size))","execution_count":181,"outputs":[{"output_type":"stream","text":"6,851 training samples\n  762 validation samples\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n\n\nbatch_size = 32\n\n \ntrain_dataloader = DataLoader(\n            train_dataset,  # The training samples.\n            sampler = RandomSampler(train_dataset), # Select batches randomly\n            batch_size = batch_size # Trains with this batch size.\n        )\n\n# For validation the order doesn't matter, so we'll just read them sequentially.\nvalidation_dataloader = DataLoader(\n            val_dataset, # The validation samples.\n            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n            batch_size = batch_size # Evaluate with this batch size.\n        )","execution_count":182,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from transformers import BertForSequenceClassification, AdamW, BertConfig\n\n# Load BertForSequenceClassification, the pretrained BERT model with a single \n# linear classification layer on top. \nmodel = BertForSequenceClassification.from_pretrained(\n    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n    num_labels = 2, # The number of output labels--2 for binary classification.\n                    # You can increase this for multi-class tasks.   \n    output_attentions = False, # Whether the model returns attentions weights.\n    output_hidden_states = False, # Whether the model returns all hidden-states.\n)\n\n# Tell pytorch to run this model on the GPU.\nmodel.cuda()","execution_count":183,"outputs":[{"output_type":"execute_result","execution_count":183,"data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get all of the model's parameters as a list of tuples.\nparams = list(model.named_parameters())\n\nprint('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n\nprint('==== Embedding Layer ====\\n')\n\nfor p in params[0:5]:\n    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n\nprint('\\n==== First Transformer ====\\n')\n\nfor p in params[5:21]:\n    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n\nprint('\\n==== Output Layer ====\\n')\n\nfor p in params[-4:]:\n    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))","execution_count":184,"outputs":[{"output_type":"stream","text":"The BERT model has 201 different named parameters.\n\n==== Embedding Layer ====\n\nbert.embeddings.word_embeddings.weight                  (30522, 768)\nbert.embeddings.position_embeddings.weight                (512, 768)\nbert.embeddings.token_type_embeddings.weight                (2, 768)\nbert.embeddings.LayerNorm.weight                              (768,)\nbert.embeddings.LayerNorm.bias                                (768,)\n\n==== First Transformer ====\n\nbert.encoder.layer.0.attention.self.query.weight          (768, 768)\nbert.encoder.layer.0.attention.self.query.bias                (768,)\nbert.encoder.layer.0.attention.self.key.weight            (768, 768)\nbert.encoder.layer.0.attention.self.key.bias                  (768,)\nbert.encoder.layer.0.attention.self.value.weight          (768, 768)\nbert.encoder.layer.0.attention.self.value.bias                (768,)\nbert.encoder.layer.0.attention.output.dense.weight        (768, 768)\nbert.encoder.layer.0.attention.output.dense.bias              (768,)\nbert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\nbert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\nbert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\nbert.encoder.layer.0.intermediate.dense.bias                 (3072,)\nbert.encoder.layer.0.output.dense.weight                 (768, 3072)\nbert.encoder.layer.0.output.dense.bias                        (768,)\nbert.encoder.layer.0.output.LayerNorm.weight                  (768,)\nbert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n\n==== Output Layer ====\n\nbert.pooler.dense.weight                                  (768, 768)\nbert.pooler.dense.bias                                        (768,)\nclassifier.weight                                           (2, 768)\nclassifier.bias                                                 (2,)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n# I believe the 'W' stands for 'Weight Decay fix\"\noptimizer = AdamW(model.parameters(),\n                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n                )\n","execution_count":185,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from transformers import get_linear_schedule_with_warmup\n\n# Number of training epochs. The BERT authors recommend between 2 and 4. \n# We chose to run for 4, but we'll see later that this may be over-fitting the\n# training data.\nepochs = 4\n\n# Total number of training steps is [number of batches] x [number of epochs]. \n# (Note that this is not the same as the number of training samples).\ntotal_steps = len(train_dataloader) * epochs\n\n# Create the learning rate scheduler.\nscheduler = get_linear_schedule_with_warmup(optimizer, \n                                            num_warmup_steps = 0, # Default value in run_glue.py\n                                            num_training_steps = total_steps)","execution_count":186,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n\n# Function to calculate the accuracy of our predictions vs labels\ndef flat_accuracy(preds, labels):\n    pred_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    return np.sum(pred_flat == labels_flat) / len(labels_flat)","execution_count":187,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nimport datetime\n\ndef format_time(elapsed):\n    '''\n    Takes a time in seconds and returns a string hh:mm:ss\n    '''\n    # Round to the nearest second.\n    elapsed_rounded = int(round((elapsed)))\n    \n    # Format as hh:mm:ss\n    return str(datetime.timedelta(seconds=elapsed_rounded))\n","execution_count":188,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\nimport numpy as np\n\n# This training code is based on the `run_glue.py` script here:\n# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n\n# Set the seed value all over the place to make this reproducible.\nseed_val = 35\n\nrandom.seed(seed_val)\nnp.random.seed(seed_val)\ntorch.manual_seed(seed_val)\ntorch.cuda.manual_seed_all(seed_val)\n\n# We'll store a number of quantities such as training and validation loss, \n# validation accuracy, and timings.\ntraining_stats = []\n\n# Measure the total training time for the whole run.\ntotal_t0 = time.time()\n\n# For each epoch...\nfor epoch_i in range(0, epochs):\n    \n    # ========================================\n    #               Training\n    # ========================================\n    \n    # Perform one full pass over the training set.\n\n    print(\"\")\n    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n    print('Training...')\n\n    # Measure how long the training epoch takes.\n    t0 = time.time()\n\n    # Reset the total loss for this epoch.\n    total_train_loss = 0\n\n    # Put the model into training mode. Don't be mislead--the call to \n    # `train` just changes the *mode*, it doesn't *perform* the training.\n    # `dropout` and `batchnorm` layers behave differently during training\n    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n    model.train()\n\n    # For each batch of training data...\n    for step, batch in enumerate(train_dataloader):\n\n        # Progress update every 40 batches.\n        if step % 40 == 0 and not step == 0:\n            # Calculate elapsed time in minutes.\n            elapsed = format_time(time.time() - t0)\n            \n            # Report progress.\n            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n\n        # Unpack this training batch from our dataloader. \n        #\n        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n        # `to` method.\n        #\n        # `batch` contains three pytorch tensors:\n        #   [0]: input ids \n        #   [1]: attention masks\n        #   [2]: labels \n        b_input_ids = batch[0].to(device)\n        b_input_mask = batch[1].to(device)\n        b_labels = batch[2].to(device)\n\n        # Always clear any previously calculated gradients before performing a\n        # backward pass. PyTorch doesn't do this automatically because \n        # accumulating the gradients is \"convenient while training RNNs\". \n        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n        model.zero_grad()        \n\n        # Perform a forward pass (evaluate the model on this training batch).\n        # The documentation for this `model` function is here: \n        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n        # It returns different numbers of parameters depending on what arguments\n        # arge given and what flags are set. For our useage here, it returns\n        # the loss (because we provided labels) and the \"logits\"--the model\n        # outputs prior to activation.\n        loss, logits = model(b_input_ids, \n                             token_type_ids=None, \n                             attention_mask=b_input_mask, \n                             labels=b_labels)\n\n        # Accumulate the training loss over all of the batches so that we can\n        # calculate the average loss at the end. `loss` is a Tensor containing a\n        # single value; the `.item()` function just returns the Python value \n        # from the tensor.\n        total_train_loss += loss.item()\n\n        # Perform a backward pass to calculate the gradients.\n        loss.backward()\n\n        # Clip the norm of the gradients to 1.0.\n        # This is to help prevent the \"exploding gradients\" problem.\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n\n        # Update parameters and take a step using the computed gradient.\n        # The optimizer dictates the \"update rule\"--how the parameters are\n        # modified based on their gradients, the learning rate, etc.\n        optimizer.step()\n\n        # Update the learning rate.\n        scheduler.step()\n\n    # Calculate the average loss over all of the batches.\n    avg_train_loss = total_train_loss / len(train_dataloader)            \n    \n    # Measure how long this epoch took.\n    training_time = format_time(time.time() - t0)\n\n    print(\"\")\n    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n    print(\"  Training epcoh took: {:}\".format(training_time))\n        \n    # ========================================\n    #               Validation\n    # ========================================\n    # After the completion of each training epoch, measure our performance on\n    # our validation set.\n\n    print(\"\")\n    print(\"Running Validation...\")\n\n    t0 = time.time()\n\n    # Put the model in evaluation mode--the dropout layers behave differently\n    # during evaluation.\n    model.eval()\n\n    # Tracking variables \n    total_eval_accuracy = 0\n    total_eval_loss = 0\n    nb_eval_steps = 0\n\n    # Evaluate data for one epoch\n    for batch in validation_dataloader:\n        \n        # Unpack this training batch from our dataloader. \n        #\n        # As we unpack the batch, we'll also copy each tensor to the GPU using \n        # the `to` method.\n        #\n        # `batch` contains three pytorch tensors:\n        #   [0]: input ids \n        #   [1]: attention masks\n        #   [2]: labels \n        b_input_ids = batch[0].to(device)\n        b_input_mask = batch[1].to(device)\n        b_labels = batch[2].to(device)\n        \n        # Tell pytorch not to bother with constructing the compute graph during\n        # the forward pass, since this is only needed for backprop (training).\n        with torch.no_grad():        \n\n            # Forward pass, calculate logit predictions.\n            # token_type_ids is the same as the \"segment ids\", which \n            # differentiates sentence 1 and 2 in 2-sentence tasks.\n            # The documentation for this `model` function is here: \n            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n            # Get the \"logits\" output by the model. The \"logits\" are the output\n            # values prior to applying an activation function like the softmax.\n            (loss, logits) = model(b_input_ids, \n                                   token_type_ids=None, \n                                   attention_mask=b_input_mask,\n                                   labels=b_labels)\n            \n        # Accumulate the validation loss.\n        total_eval_loss += loss.item()\n\n        # Move logits and labels to CPU\n        logits = logits.detach().cpu().numpy()\n        label_ids = b_labels.to('cpu').numpy()\n\n        # Calculate the accuracy for this batch of test sentences, and\n        # accumulate it over all batches.\n        total_eval_accuracy += flat_accuracy(logits, label_ids)\n        \n\n    # Report the final accuracy for this validation run.\n    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n\n    # Calculate the average loss over all of the batches.\n    avg_val_loss = total_eval_loss / len(validation_dataloader)\n    \n    # Measure how long the validation run took.\n    validation_time = format_time(time.time() - t0)\n    \n    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n    print(\"  Validation took: {:}\".format(validation_time))\n\n    # Record all statistics from this epoch.\n    training_stats.append(\n        {\n            'epoch': epoch_i + 1,\n            'Training Loss': avg_train_loss,\n            'Valid. Loss': avg_val_loss,\n            'Valid. Accur.': avg_val_accuracy,\n            'Training Time': training_time,\n            'Validation Time': validation_time\n        }\n    )\n\nprint(\"\")\nprint(\"Training complete!\")\n\nprint(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))","execution_count":189,"outputs":[{"output_type":"stream","text":"\n======== Epoch 1 / 4 ========\nTraining...\n  Batch    40  of    215.    Elapsed: 0:00:07.\n  Batch    80  of    215.    Elapsed: 0:00:14.\n  Batch   120  of    215.    Elapsed: 0:00:22.\n  Batch   160  of    215.    Elapsed: 0:00:29.\n  Batch   200  of    215.    Elapsed: 0:00:36.\n\n  Average training loss: 0.45\n  Training epcoh took: 0:00:39\n\nRunning Validation...\n  Accuracy: 0.82\n  Validation Loss: 0.43\n  Validation took: 0:00:01\n\n======== Epoch 2 / 4 ========\nTraining...\n  Batch    40  of    215.    Elapsed: 0:00:07.\n  Batch    80  of    215.    Elapsed: 0:00:15.\n  Batch   120  of    215.    Elapsed: 0:00:22.\n  Batch   160  of    215.    Elapsed: 0:00:29.\n  Batch   200  of    215.    Elapsed: 0:00:37.\n\n  Average training loss: 0.34\n  Training epcoh took: 0:00:39\n\nRunning Validation...\n  Accuracy: 0.82\n  Validation Loss: 0.42\n  Validation took: 0:00:01\n\n======== Epoch 3 / 4 ========\nTraining...\n  Batch    40  of    215.    Elapsed: 0:00:07.\n  Batch    80  of    215.    Elapsed: 0:00:15.\n  Batch   120  of    215.    Elapsed: 0:00:22.\n  Batch   160  of    215.    Elapsed: 0:00:29.\n  Batch   200  of    215.    Elapsed: 0:00:37.\n\n  Average training loss: 0.26\n  Training epcoh took: 0:00:39\n\nRunning Validation...\n  Accuracy: 0.81\n  Validation Loss: 0.46\n  Validation took: 0:00:01\n\n======== Epoch 4 / 4 ========\nTraining...\n  Batch    40  of    215.    Elapsed: 0:00:07.\n  Batch    80  of    215.    Elapsed: 0:00:14.\n  Batch   120  of    215.    Elapsed: 0:00:22.\n  Batch   160  of    215.    Elapsed: 0:00:29.\n  Batch   200  of    215.    Elapsed: 0:00:36.\n\n  Average training loss: 0.21\n  Training epcoh took: 0:00:39\n\nRunning Validation...\n  Accuracy: 0.80\n  Validation Loss: 0.60\n  Validation took: 0:00:01\n\nTraining complete!\nTotal training took 0:02:41 (h:mm:ss)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('precision', 2)\n\n# Create a DataFrame from our training statistics.\ndf_stats = pd.DataFrame(data=training_stats)\n\n# Use the 'epoch' as the row index.\ndf_stats = df_stats.set_index('epoch')\n\n# A hack to force the column headers to wrap.\n#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n\n# Display the table.\ndf_stats","execution_count":190,"outputs":[{"output_type":"execute_result","execution_count":190,"data":{"text/plain":"       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\nepoch                                                                         \n1               0.45         0.43           0.82       0:00:39         0:00:01\n2               0.34         0.42           0.82       0:00:39         0:00:01\n3               0.26         0.46           0.81       0:00:39         0:00:01\n4               0.21         0.60           0.80       0:00:39         0:00:01","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Training Loss</th>\n      <th>Valid. Loss</th>\n      <th>Valid. Accur.</th>\n      <th>Training Time</th>\n      <th>Validation Time</th>\n    </tr>\n    <tr>\n      <th>epoch</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.45</td>\n      <td>0.43</td>\n      <td>0.82</td>\n      <td>0:00:39</td>\n      <td>0:00:01</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.34</td>\n      <td>0.42</td>\n      <td>0.82</td>\n      <td>0:00:39</td>\n      <td>0:00:01</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.26</td>\n      <td>0.46</td>\n      <td>0.81</td>\n      <td>0:00:39</td>\n      <td>0:00:01</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.21</td>\n      <td>0.60</td>\n      <td>0.80</td>\n      <td>0:00:39</td>\n      <td>0:00:01</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\n\n# Use plot styling from seaborn.\nsns.set(style='darkgrid')\n\n# Increase the plot size and font size.\nsns.set(font_scale=1.5)\nplt.rcParams[\"figure.figsize\"] = (12,6)\n\n# Plot the learning curve.\nplt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\nplt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n\n# Label the plot.\nplt.title(\"Training & Validation Loss\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.xticks([1, 2, 3, 4])\n\nplt.show()","execution_count":192,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 864x432 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}